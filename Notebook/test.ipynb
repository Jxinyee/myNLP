{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_leftweight = Variable(nn.init.uniform_(torch.randn(5,4), a=0, b=0.1),requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_left = Variable(torch.randn(5,5),requires_grad= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " y =context_left.mm(embeding_leftweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-fe54e5c70885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "y.backward(torch.ones(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1813, 0.2358, 0.2678, 0.2545, 0.1507],\n        [0.1813, 0.2358, 0.2678, 0.2545, 0.1507],\n        [0.1813, 0.2358, 0.2678, 0.2545, 0.1507],\n        [0.1813, 0.2358, 0.2678, 0.2545, 0.1507],\n        [0.1813, 0.2358, 0.2678, 0.2545, 0.1507]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_left.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5651, -1.1551, -0.5496,  1.6537, -0.1682],\n        [ 0.2507,  0.3130, -0.6467,  1.5113, -0.3673],\n        [-0.3354,  1.0079,  0.0147,  0.5377,  0.5452],\n        [ 0.0966,  0.1328, -0.5117,  0.2207,  0.8816],\n        [ 0.2905,  1.7970,  0.4214,  0.1812,  0.0208]], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8675,  0.8675,  0.8675,  0.8675],\n        [ 2.0957,  2.0957,  2.0957,  2.0957],\n        [-1.2719, -1.2719, -1.2719, -1.2719],\n        [ 4.1047,  4.1047,  4.1047,  4.1047],\n        [ 0.9121,  0.9121,  0.9121,  0.9121]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeding_leftweight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0625,  0.3005, -1.0818],\n        [-0.3279, -0.0631,  0.3954]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(2,3)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2060, -0.0485,  0.1944],\n        [ 0.6018,  0.2845, -0.7076]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5521, 0.4879, 0.5491],\n        [0.6673, 0.5726, 0.2927]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.sigmoid\n",
    "f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2090, -0.0486,  0.1969],\n        [ 0.6960,  0.2926, -0.8824]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1969])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "b = np.random.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19346252,  0.01576914, -1.79707478])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= [2,3,4,5]\n",
    "d =c.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19346252,  0.01576914, -1.79707478])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2090, -0.0486,  0.1969],\n        [ 0.6960,  0.2926, -0.8824]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(12,5,10)\n",
    "b= torch.split(a,split_size_or_sections=1, dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c= [word.squeeze(dim =1) for word in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =torch.stack(c,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5, 10])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n\n        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d== a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 10])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5, 10])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
